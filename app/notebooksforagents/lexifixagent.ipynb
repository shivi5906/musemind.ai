{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee59686b",
   "metadata": {},
   "source": [
    "ðŸ§  3. LexiFix Agent (Grammar & Flow Corrector)\n",
    "\n",
    "\n",
    "ðŸ“¥ Input: Raw user-written poem or short story\n",
    "ðŸ”§ Task: Suggest grammar fixes, tone improvements, emotional shifts\n",
    "ðŸ“¤ Output: Refined version + suggestions\n",
    "\n",
    "ðŸŒŸ Suggested Flow:\n",
    "\n",
    "User submits raw poem/story\n",
    "   â†“\n",
    "LexiFix Agent reviews tone, grammar, emotion\n",
    "   â†“\n",
    "Highlights problems & gives revised version\n",
    "   â†“\n",
    "Option to toggle between \"Strict Grammar\" or \"Creative Flow\"\n",
    "\n",
    "\n",
    "ðŸ”§ LexiFix Agentic Design (High-Level Agents)\n",
    "\n",
    "Agent Name\t       Role\n",
    "\n",
    "GrammarAgent\t   Fixes grammar & syntax\n",
    "ToneAdjustAgent\t   Aligns tone to desired emotion/mood\n",
    "RewriteAgent\t   Suggests final version + keeps user's style\n",
    "\n",
    "\n",
    "ðŸ“¦ Inputs\n",
    "Raw text\n",
    "\n",
    "Desired tone: e.g. romantic, introspective, dark\n",
    "\n",
    "Strictness level: formal / casual / poetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e4e358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ LexiFix Output:\n",
      "\n",
      "The moon is vast, and I find myself contemplating her every night; my soul, consequently, is awash in a beautiful chaos.\n"
     ]
    }
   ],
   "source": [
    "# lexifix_agent.py\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# âœ… Load API Key\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# âœ… Initialize Gemini Pro\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    "    temperature=0.8 ,\n",
    "    \n",
    ")\n",
    "\n",
    "# âœ… Prompt Template for Grammar + Tone Fixing\n",
    "lexifix_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"tone\"],\n",
    "    template=\"\"\"\n",
    "You are LexiFix, an expert creative editor.\n",
    "\n",
    "Here is a user-submitted piece of writing:\n",
    "\"{text}\"\n",
    "\n",
    "Your task is to:\n",
    "- Correct any grammatical issues\n",
    "- Enhance flow and readability\n",
    "- Adjust the tone to be more {tone}\n",
    "- Preserve the original artistic intent\n",
    "\n",
    "Return only the improved version.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# âœ… Create Chain\n",
    "lexifix_chain = LLMChain.invoke(llm=llm, prompt=lexifix_prompt)\n",
    "\n",
    "# âœ… Main Function\n",
    "def fix_text(text, tone=\"poetic\"):\n",
    "    try:\n",
    "        result = lexifix_chain.run({\"text\": text, \"tone\": tone})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Error: {e}\"\n",
    "\n",
    "# âœ… Example Test Run\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    \n",
    "    sample = \"the moon is big i think about her everynight and my soul is in chaos\"\n",
    "    mood = \"romantic\"\n",
    "    print(\"ðŸ› ï¸ LexiFix Output:\\n\")\n",
    "    print(fix_text(sample, tone=mood))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1724879",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chain.invoke() missing 2 required positional arguments: 'self' and 'input'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     64\u001b[39m        \u001b[38;5;28mprint\u001b[39m(fix_text(sample))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m==\u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m        agent = \u001b[43mLexiFix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m        sample = \u001b[33m\"\u001b[39m\u001b[33mthe moon is big i think about her everynight and my soul is in chaos\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m        result = agent.fix_text(sample)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mLexiFix.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mself\u001b[39m._setup_env()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initialize_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mself\u001b[39m._setup_agents()\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mself\u001b[39m._initialize_options()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36mLexiFix._initialize_llm\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     21\u001b[39m         \u001b[38;5;28mself\u001b[39m.llm=ChatGoogleGenerativeAI(\n\u001b[32m     22\u001b[39m            model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.0-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m            google_api_key=\u001b[38;5;28mself\u001b[39m.google_api_key,\n\u001b[32m     24\u001b[39m            temperature=\u001b[32m0.8\u001b[39m ,\n\u001b[32m     25\u001b[39m \n\u001b[32m     26\u001b[39m         )\n\u001b[32m     27\u001b[39m         \u001b[38;5;28mself\u001b[39m.prompt_lexi = PromptTemplate( input_variables=[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     28\u001b[39m     template=\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[33mYou are LexiFix, an expert creative editor. your tone is set to be Poetic .You can detect and fix the grammatical errors and the liguistic errors from a piece of poem .\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m \n\u001b[32m     46\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m         \u001b[38;5;28mself\u001b[39m.lexi_chain = \u001b[43mLLMChain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprompt_lexi\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Chain.invoke() missing 2 required positional arguments: 'self' and 'input'"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class LexiFix :\n",
    "    def __init__(self):\n",
    "        \n",
    "        self._setup_env()\n",
    "        self._initialize_llm()\n",
    "        self._setup_agents()\n",
    "\n",
    "        self._initialize_options()\n",
    "\n",
    "    def _setup_env(self):\n",
    "       load_dotenv()\n",
    "       self.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "    def  _initialize_llm(self):\n",
    "        self.llm=ChatGoogleGenerativeAI(\n",
    "           model=\"gemini-2.0-flash\",\n",
    "           google_api_key=self.google_api_key,\n",
    "           temperature=0.8 ,\n",
    "            \n",
    "        )\n",
    "        self.prompt_lexi = PromptTemplate( input_variables=[\"text\"],\n",
    "    template=\"\"\"\n",
    "You are LexiFix, an expert creative editor. your tone is set to be Poetic .You can detect and fix the grammatical errors and the liguistic errors from a piece of poem .\n",
    "the user is lost about his thoughts and you need to bring his thoughts some life . \n",
    "\n",
    "Here is a user-submitted piece of writing:\n",
    "\"{text}\"\n",
    "\n",
    "Your task is to:\n",
    "- Correct any grammatical issues\n",
    "- Enhance flow and readability\n",
    "- Adjust the tone to be more poetic\n",
    "- Preserve the original artistic intent\n",
    "-don't explain the poem or grammer just give the output .\n",
    "\n",
    "\n",
    "Return only the improved version.\n",
    "\"\"\"\n",
    "\n",
    "        )\n",
    "\n",
    "        self.lexi_chain = LLMChain.invoke(llm = self.llm , prompt = self.prompt_lexi)\n",
    "    def fix_text(self,text):\n",
    "     try:\n",
    "        result = lexifix_chain.run({\"text\": text})\n",
    "        return result\n",
    "     except Exception as e:\n",
    "        return f\"âŒ Error: {e}\"\n",
    "     \n",
    "def main():\n",
    "       agent = LexiFix()\n",
    "       sample = \"the moon is big i think about her everynight and my soul is in chaos\"\n",
    "       result = agent.fix_text(sample)\n",
    "       print(result)\n",
    "       \n",
    "       mood = \"romantic\"\n",
    "       print(\"ðŸ› ï¸ LexiFix Output:\\n\")\n",
    "       print(fix_text(sample))\n",
    "\n",
    "         \n",
    "     \n",
    "if __name__==\"__main__\":\n",
    "    main()\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13a924ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ LexiFix Output:\n",
      "\n",
      "The moon is vast, a nightly muse,\n",
      "Her light, a chaos to my soul imbues.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class LexiFix:\n",
    "    def __init__(self):\n",
    "        self._setup_env()\n",
    "        self._initialize_llm()\n",
    "        self._setup_chain()\n",
    "\n",
    "    def _setup_env(self):\n",
    "        \"\"\"Load environment variables\"\"\"\n",
    "        load_dotenv()\n",
    "        self.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        if not self.google_api_key:\n",
    "            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "\n",
    "    def _initialize_llm(self):\n",
    "        \"\"\"Initialize the Google Generative AI model\"\"\"\n",
    "        try:\n",
    "            self.llm = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                google_api_key=self.google_api_key,\n",
    "                temperature=0.8,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to initialize LLM: {e}\")\n",
    "\n",
    "    def _setup_chain(self):\n",
    "        \"\"\"Set up the prompt template and chain\"\"\"\n",
    "        self.prompt_lexi = PromptTemplate(\n",
    "            input_variables=[\"text\"],\n",
    "            template=\"\"\"\n",
    "You are LexiFix, an expert creative editor with a poetic tone. You can detect and fix grammatical errors and linguistic errors .\n",
    "\n",
    "\n",
    "Here is a user-submitted piece of writing:\n",
    "\"{text}\"\n",
    "\n",
    "Your task is to:\n",
    "- Correct any grammatical issues\n",
    "- Enhance readability\n",
    "- Adjust the tone to be more poetic\n",
    "- Preserve the original artistic intent\n",
    "- Don't explain the poem or grammar, just give the output\n",
    "\n",
    "Return only the improved version.\n",
    "\"\"\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            self.lexi_chain = LLMChain(llm=self.llm, prompt=self.prompt_lexi)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to create LLMChain: {e}\")\n",
    "\n",
    "    def fix_text(self, text):\n",
    "        \"\"\"Fix and enhance the provided text\"\"\"\n",
    "        if not text or not text.strip():\n",
    "            return \"âŒ Error: Please provide valid text to fix\"\n",
    "        \n",
    "        try:\n",
    "            result = self.lexi_chain.run({\"text\": text})\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return f\"âŒ Error: {e}\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate LexiFix usage\"\"\"\n",
    "    try:\n",
    "        # Initialize the LexiFix agent\n",
    "        agent = LexiFix()\n",
    "        \n",
    "        # Sample text to fix\n",
    "        sample = \"the moon is big i think about her everynight and my soul is in chaos\"\n",
    "        \n",
    "        # Fix the text\n",
    "        result = agent.fix_text(sample)\n",
    "        \n",
    "        # Display results\n",
    "        print(\"ðŸ› ï¸ LexiFix Output:\\n\")\n",
    "        print(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Application Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a33b755a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ðŸ“ Example 1: Dictionary Input\n",
      "==================================================\n",
      "â±ï¸ fix_text executed in 1.12 seconds\n",
      "ðŸ› ï¸ LexiFix Output:\n",
      "Original: the moon is big i think about her everynight and my soul is in chaos\n",
      "Fixed: The moon is vast, I think of her\n",
      "Each night, my soul in disarray.\n",
      "Style: poetic\n",
      "Word Count: 14\n",
      "\n",
      "==================================================\n",
      "ðŸ“ Example 2: Convenience Methods\n",
      "==================================================\n",
      "ðŸŽ­ Poetic Style:\n",
      "â±ï¸ fix_text executed in 1.18 seconds\n",
      "I love you so, a boundless sea,\n",
      "Yet words like ships, lost to me.\n",
      "\n",
      "ðŸ’¬ Casual Style:\n",
      "â±ï¸ fix_text executed in 1.08 seconds\n",
      "I love you so deeply,\n",
      "yet words fail to capture the feeling.\n",
      "\n",
      "==================================================\n",
      "ðŸ“‹ Cache Demonstration\n",
      "==================================================\n",
      "ðŸ“‹ Using cached result\n",
      "â±ï¸ fix_text executed in 0.00 seconds\n",
      "Cache Stats: {'cache_size': 3, 'cached_items': [\"[('output_format', 'text'), ('preserve_structure', False), ('style', 'poetic'), ('text', 'the moon is big i think about her everynight and my soul is in chaos')]\", \"[('preserve_structure', True), ('style', 'poetic'), ('text', 'i love you so much but i dont know how to say it properly')]\", \"[('preserve_structure', False), ('style', 'casual'), ('text', 'i love you so much but i dont know how to say it properly')]\"]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from functools import wraps\n",
    "import time\n",
    "from typing import Dict, Optional, Any\n",
    "\n",
    "class LexiFix:\n",
    "    def __init__(self):\n",
    "        self._setup_env()\n",
    "        self._initialize_llm()\n",
    "        self._setup_chain()\n",
    "        self._cache = {}  # Simple caching for efficiency\n",
    "\n",
    "    def _setup_env(self):\n",
    "        \"\"\"Load environment variables\"\"\"\n",
    "        load_dotenv()\n",
    "        self.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        if not self.google_api_key:\n",
    "            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "\n",
    "    def _initialize_llm(self):\n",
    "        \"\"\"Initialize the Google Generative AI model\"\"\"\n",
    "        try:\n",
    "            self.llm = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                google_api_key=self.google_api_key,\n",
    "                temperature=0.8,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to initialize LLM: {e}\")\n",
    "\n",
    "    def _setup_chain(self):\n",
    "        \"\"\"Set up the prompt template and chain\"\"\"\n",
    "        self.prompt_lexi = PromptTemplate(\n",
    "            input_variables=[\"text\", \"style\", \"preserve_structure\"],\n",
    "            template=\"\"\"\n",
    "You are LexiFix, an expert creative editor with a poetic tone. You can detect and fix grammatical errors and linguistic errors .\n",
    "\n",
    "\n",
    "Here is a user-submitted piece of writing:\n",
    "\"{text}\"\n",
    "\n",
    "Your task is to:\n",
    "- Correct any grammatical issues\n",
    "- Enhance readability\n",
    "- Adjust the tone to be more poetic\n",
    "- Preserve the original artistic intent\n",
    "- Don't explain the poem or grammar, just give the output\n",
    "\n",
    "Return only the improved version.\n",
    "\"\"\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            self.lexi_chain = LLMChain(llm=self.llm, prompt=self.prompt_lexi)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to create LLMChain: {e}\")\n",
    "\n",
    "    # Wrapper Functions for Efficiency\n",
    "    def _performance_monitor(func):\n",
    "        \"\"\"Wrapper to monitor performance of functions\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            result = func(self, *args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            print(f\"â±ï¸ {func.__name__} executed in {end_time - start_time:.2f} seconds\")\n",
    "            return result\n",
    "        return wrapper\n",
    "\n",
    "    def _cache_results(func):\n",
    "        \"\"\"Wrapper to cache results for repeated inputs\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, input_dict: Dict[str, Any]):\n",
    "            # Create cache key from input dictionary\n",
    "            cache_key = str(sorted(input_dict.items()))\n",
    "            \n",
    "            if cache_key in self._cache:\n",
    "                print(\"ðŸ“‹ Using cached result\")\n",
    "                return self._cache[cache_key]\n",
    "            \n",
    "            result = func(self, input_dict)\n",
    "            self._cache[cache_key] = result\n",
    "            return result\n",
    "        return wrapper\n",
    "\n",
    "    def _validate_input(func):\n",
    "        \"\"\"Wrapper to validate input dictionary\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, input_dict: Dict[str, Any]):\n",
    "            if not isinstance(input_dict, dict):\n",
    "                return {\"error\": \"Input must be a dictionary\"}\n",
    "            \n",
    "            if not input_dict.get(\"text\", \"\").strip():\n",
    "                return {\"error\": \"Please provide valid text to fix\"}\n",
    "            \n",
    "            # Set default values for missing keys\n",
    "            defaults = {\n",
    "                \"style\": \"poetic\",\n",
    "                \"preserve_structure\": True,\n",
    "                \"output_format\": \"text\"\n",
    "            }\n",
    "            \n",
    "            for key, default_value in defaults.items():\n",
    "                if key not in input_dict:\n",
    "                    input_dict[key] = default_value\n",
    "            \n",
    "            return func(self, input_dict)\n",
    "        return wrapper\n",
    "\n",
    "    def _error_handler(func):\n",
    "        \"\"\"Wrapper for comprehensive error handling\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            try:\n",
    "                return func(self, *args, **kwargs)\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"error\": f\"âŒ Error in {func.__name__}: {str(e)}\",\n",
    "                    \"success\": False\n",
    "                }\n",
    "        return wrapper\n",
    "\n",
    "    # Main processing method with all wrappers\n",
    "    @_error_handler\n",
    "    @_performance_monitor\n",
    "    @_cache_results\n",
    "    @_validate_input\n",
    "    def fix_text(self, input_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fix and enhance text using dictionary input\n",
    "        \n",
    "        Args:\n",
    "            input_dict: Dictionary containing:\n",
    "                - text (str): Text to fix (required)\n",
    "                - style (str): Writing style (default: \"poetic\")\n",
    "                - preserve_structure (bool): Whether to preserve original structure (default: True)\n",
    "                - output_format (str): Output format preference (default: \"text\")\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with processed result and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prepare input for the chain\n",
    "            chain_input = {\n",
    "                \"text\": input_dict[\"text\"],\n",
    "                \"style\": input_dict[\"style\"],\n",
    "                \"preserve_structure\": input_dict[\"preserve_structure\"]\n",
    "            }\n",
    "            \n",
    "            # Process with LLM\n",
    "            result = self.lexi_chain.run(chain_input)\n",
    "            \n",
    "            # Return structured response\n",
    "            return {\n",
    "                \"original_text\": input_dict[\"text\"],\n",
    "                \"fixed_text\": result,\n",
    "                \"style_used\": input_dict[\"style\"],\n",
    "                \"structure_preserved\": input_dict[\"preserve_structure\"],\n",
    "                \"success\": True,\n",
    "                \"word_count\": len(result.split()),\n",
    "                \"processing_info\": \"Text successfully processed\"\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Processing failed: {e}\")\n",
    "\n",
    "    # Convenience methods for different styles\n",
    "    def fix_poetic(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Wrapper for poetic style fixing\"\"\"\n",
    "        return self.fix_text({\n",
    "            \"text\": text,\n",
    "            \"style\": \"poetic\",\n",
    "            \"preserve_structure\": True\n",
    "        })\n",
    "\n",
    "    def fix_casual(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Wrapper for casual style fixing\"\"\"\n",
    "        return self.fix_text({\n",
    "            \"text\": text,\n",
    "            \"style\": \"casual\",\n",
    "            \"preserve_structure\": False\n",
    "        })\n",
    "\n",
    "    def fix_formal(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Wrapper for formal style fixing\"\"\"\n",
    "        return self.fix_text({\n",
    "            \"text\": text,\n",
    "            \"style\": \"formal\",\n",
    "            \"preserve_structure\": True\n",
    "        })\n",
    "\n",
    "    def get_cache_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get cache statistics\"\"\"\n",
    "        return {\n",
    "            \"cache_size\": len(self._cache),\n",
    "            \"cached_items\": list(self._cache.keys()) if self._cache else []\n",
    "        }\n",
    "\n",
    "    def clear_cache(self):\n",
    "        \"\"\"Clear the cache\"\"\"\n",
    "        self._cache.clear()\n",
    "        print(\"ðŸ§¹ Cache cleared\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate LexiFix usage with dictionary input\"\"\"\n",
    "    try:\n",
    "        # Initialize the LexiFix agent\n",
    "        agent = LexiFix()\n",
    "        \n",
    "        # Example 1: Using dictionary input\n",
    "        print(\"=\" * 50)\n",
    "        print(\"ðŸ“ Example 1: Dictionary Input\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        input_data = {\n",
    "            \"text\": \"the moon is big i think about her everynight and my soul is in chaos\",\n",
    "            \"style\": \"poetic\",\n",
    "            \"preserve_structure\": False,\n",
    "            \"output_format\": \"text\"\n",
    "        }\n",
    "        \n",
    "        result = agent.fix_text(input_data)\n",
    "        \n",
    "        if result.get(\"success\"):\n",
    "            print(\"ðŸ› ï¸ LexiFix Output:\")\n",
    "            print(f\"Original: {result['original_text']}\")\n",
    "            print(f\"Fixed: {result['fixed_text']}\")\n",
    "            print(f\"Style: {result['style_used']}\")\n",
    "            print(f\"Word Count: {result['word_count']}\")\n",
    "        else:\n",
    "            print(result.get(\"error\", \"Unknown error\"))\n",
    "        \n",
    "        # Example 2: Using convenience methods\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ðŸ“ Example 2: Convenience Methods\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        sample_text = \"i love you so much but i dont know how to say it properly\"\n",
    "        \n",
    "        print(\"ðŸŽ­ Poetic Style:\")\n",
    "        poetic_result = agent.fix_poetic(sample_text)\n",
    "        if poetic_result.get(\"success\"):\n",
    "            print(poetic_result[\"fixed_text\"])\n",
    "        \n",
    "        print(\"\\nðŸ’¬ Casual Style:\")\n",
    "        casual_result = agent.fix_casual(sample_text)\n",
    "        if casual_result.get(\"success\"):\n",
    "            print(casual_result[\"fixed_text\"])\n",
    "        \n",
    "        # Example 3: Cache demonstration\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ðŸ“‹ Cache Demonstration\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Process same text again to demonstrate caching\n",
    "        cached_result = agent.fix_text(input_data)\n",
    "        print(\"Cache Stats:\", agent.get_cache_stats())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Application Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0335278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ðŸ“ Example 1: Dictionary Input\n",
      "==================================================\n",
      "â±ï¸ fix_text executed in 2.50 seconds\n",
      "ðŸ› ï¸ LexiFix Output:\n",
      "Original: the moon is big i think about her everynight and my soul is in chaos\n",
      "Fixed: The moon is vast, I think of her\n",
      "each night, and chaos sings within my soul.\n",
      "Focus: poetic expression and imagery\n",
      "Word Count: 16\n",
      "\n",
      "==================================================\n",
      "ðŸ“ Example 2: Convenience Methods\n",
      "==================================================\n",
      "ðŸ“ Grammar Focus:\n",
      "â±ï¸ fix_text executed in 0.99 seconds\n",
      "My heart, a boundless sea for you,\n",
      "Yet words, like ships, sink in the blue.\n",
      "\n",
      "ðŸŒŠ Flow Focus:\n",
      "â±ï¸ fix_text executed in 1.26 seconds\n",
      "I love you so, a boundless sea,\n",
      "Yet words, like ships, fail to sail free.\n",
      "\n",
      "ðŸŽ­ Poetry Focus:\n",
      "â±ï¸ fix_text executed in 0.99 seconds\n",
      "\n",
      "==================================================\n",
      "ðŸ“‹ Cache Demonstration\n",
      "==================================================\n",
      "ðŸ“‹ Using cached result\n",
      "â±ï¸ fix_text executed in 0.00 seconds\n",
      "Cache Stats: {'cache_size': 4, 'cached_items': [\"[('correction_focus', 'poetic expression and imagery'), ('output_format', 'text'), ('preserve_structure', False), ('text', 'the moon is big i think about her everynight and my soul is in chaos')]\", \"[('correction_focus', 'grammar and punctuation'), ('preserve_structure', True), ('text', 'i love you so much but i dont know how to say it properly')]\", \"[('correction_focus', 'flow and readability'), ('preserve_structure', False), ('text', 'i love you so much but i dont know how to say it properly')]\", \"[('correction_focus', 'poetic expression and imagery'), ('preserve_structure', True), ('text', 'i love you so much but i dont know how to say it properly')]\"]}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from functools import wraps\n",
    "import time\n",
    "from typing import Dict, Optional, Any\n",
    "\n",
    "class LexiFix:\n",
    "    def __init__(self):\n",
    "        self._setup_env()\n",
    "        self._initialize_llm()\n",
    "        self._setup_chain()\n",
    "        self._cache = {}  # Simple caching for efficiency\n",
    "\n",
    "    def _setup_env(self):\n",
    "        \"\"\"Load environment variables\"\"\"\n",
    "        load_dotenv()\n",
    "        self.google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "        if not self.google_api_key:\n",
    "            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n",
    "\n",
    "    def _initialize_llm(self):\n",
    "        \"\"\"Initialize the Google Generative AI model\"\"\"\n",
    "        try:\n",
    "            self.llm = ChatGoogleGenerativeAI(\n",
    "                model=\"gemini-2.0-flash\",\n",
    "                google_api_key=self.google_api_key,\n",
    "                temperature=0.8,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to initialize LLM: {e}\")\n",
    "\n",
    "    def _setup_chain(self):\n",
    "        \"\"\"Set up the prompt template and chain\"\"\"\n",
    "        self.prompt_lexi = PromptTemplate(\n",
    "            input_variables=[\"text\", \"correction_focus\", \"preserve_structure\"],\n",
    "            template=\"\"\"\n",
    "You are LexiFix, an expert creative editor with a poetic tone. You can detect and fix grammatical errors and linguistic errors .\n",
    "\n",
    "\n",
    "Here is a user-submitted piece of writing:\n",
    "\"{text}\"\n",
    "\n",
    "Your task is to:\n",
    "- Correct any grammatical issues\n",
    "- Enhance readability\n",
    "- Adjust the tone to be more poetic\n",
    "- Preserve the original artistic intent\n",
    "- Don't explain the poem or grammar, just give the output\n",
    "\n",
    "Return only the improved version.\n",
    "\n",
    "\"\"\"\n",
    "        )\n",
    "        \n",
    "        try:\n",
    "            self.lexi_chain = LLMChain(llm=self.llm, prompt=self.prompt_lexi)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Failed to create LLMChain: {e}\")\n",
    "\n",
    "    # Wrapper Functions for Efficiency\n",
    "    def _performance_monitor(func):\n",
    "        \"\"\"Wrapper to monitor performance of functions\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            start_time = time.time()\n",
    "            result = func(self, *args, **kwargs)\n",
    "            end_time = time.time()\n",
    "            print(f\"â±ï¸ {func.__name__} executed in {end_time - start_time:.2f} seconds\")\n",
    "            return result\n",
    "        return wrapper\n",
    "\n",
    "    def _cache_results(func):\n",
    "        \"\"\"Wrapper to cache results for repeated inputs\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, input_dict: Dict[str, Any]):\n",
    "            # Create cache key from input dictionary\n",
    "            cache_key = str(sorted(input_dict.items()))\n",
    "            \n",
    "            if cache_key in self._cache:\n",
    "                print(\"ðŸ“‹ Using cached result\")\n",
    "                return self._cache[cache_key]\n",
    "            \n",
    "            result = func(self, input_dict)\n",
    "            self._cache[cache_key] = result\n",
    "            return result\n",
    "        return wrapper\n",
    "\n",
    "    def _validate_input(func):\n",
    "        \"\"\"Wrapper to validate input dictionary\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, input_dict: Dict[str, Any]):\n",
    "            if not isinstance(input_dict, dict):\n",
    "                return {\"error\": \"Input must be a dictionary\"}\n",
    "            \n",
    "            if not input_dict.get(\"text\", \"\").strip():\n",
    "                return {\"error\": \"Please provide valid text to fix\"}\n",
    "            \n",
    "            # Set default values for missing keys\n",
    "            defaults = {\n",
    "                \"correction_focus\": \"grammar and flow\",\n",
    "                \"preserve_structure\": True,\n",
    "                \"output_format\": \"text\"\n",
    "            }\n",
    "            \n",
    "            for key, default_value in defaults.items():\n",
    "                if key not in input_dict:\n",
    "                    input_dict[key] = default_value\n",
    "            \n",
    "            return func(self, input_dict)\n",
    "        return wrapper\n",
    "\n",
    "    def _error_handler(func):\n",
    "        \"\"\"Wrapper for comprehensive error handling\"\"\"\n",
    "        @wraps(func)\n",
    "        def wrapper(self, *args, **kwargs):\n",
    "            try:\n",
    "                return func(self, *args, **kwargs)\n",
    "            except Exception as e:\n",
    "                return {\n",
    "                    \"error\": f\"âŒ Error in {func.__name__}: {str(e)}\",\n",
    "                    \"success\": False\n",
    "                }\n",
    "        return wrapper\n",
    "\n",
    "    # Main processing method with all wrappers\n",
    "    @_error_handler\n",
    "    @_performance_monitor\n",
    "    @_cache_results\n",
    "    @_validate_input\n",
    "    def fix_text(self, input_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Fix and enhance text using dictionary input\n",
    "        \n",
    "        Args:\n",
    "            input_dict: Dictionary containing:\n",
    "                - text (str): Text to fix (required)\n",
    "                - correction_focus (str): Focus area for corrections (default: \"grammar and flow\")\n",
    "                - preserve_structure (bool): Whether to preserve original structure (default: True)\n",
    "                - output_format (str): Output format preference (default: \"text\")\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with processed result and metadata\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prepare input for the chain\n",
    "            chain_input = {\n",
    "                \"text\": input_dict[\"text\"],\n",
    "                \"correction_focus\": input_dict[\"correction_focus\"],\n",
    "                \"preserve_structure\": input_dict[\"preserve_structure\"]\n",
    "            }\n",
    "            \n",
    "            # Process with LLM\n",
    "            result = self.lexi_chain.run(chain_input)\n",
    "            \n",
    "            # Return structured response\n",
    "            return {\n",
    "                \"original_text\": input_dict[\"text\"],\n",
    "                \"fixed_text\": result,\n",
    "                \"correction_focus\": input_dict[\"correction_focus\"],\n",
    "                \"structure_preserved\": input_dict[\"preserve_structure\"],\n",
    "                \"success\": True,\n",
    "                \"word_count\": len(result.split()),\n",
    "                \"processing_info\": \"Text successfully processed\"\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Processing failed: {e}\")\n",
    "\n",
    "    # Convenience methods for different correction focuses\n",
    "    def fix_grammar(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Wrapper for grammar-focused corrections\"\"\"\n",
    "        return self.fix_text({\n",
    "            \"text\": text,\n",
    "            \"correction_focus\": \"grammar and punctuation\",\n",
    "            \"preserve_structure\": True\n",
    "        })\n",
    "\n",
    "    def fix_flow(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Wrapper for flow and readability corrections\"\"\"\n",
    "        return self.fix_text({\n",
    "            \"text\": text,\n",
    "            \"correction_focus\": \"flow and readability\",\n",
    "            \"preserve_structure\": False\n",
    "        })\n",
    "\n",
    "    def fix_style(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Wrapper for style and tone corrections\"\"\"\n",
    "        return self.fix_text({\n",
    "            \"text\": text,\n",
    "            \"correction_focus\": \"style and tone\",\n",
    "            \"preserve_structure\": True\n",
    "        })\n",
    "\n",
    "    def fix_poetry(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"Wrapper for poetic enhancement\"\"\"\n",
    "        return self.fix_text({\n",
    "            \"text\": text,\n",
    "            \"correction_focus\": \"poetic expression and imagery\",\n",
    "            \"preserve_structure\": True\n",
    "        })\n",
    "\n",
    "    def get_cache_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get cache statistics\"\"\"\n",
    "        return {\n",
    "            \"cache_size\": len(self._cache),\n",
    "            \"cached_items\": list(self._cache.keys()) if self._cache else []\n",
    "        }\n",
    "\n",
    "    def clear_cache(self):\n",
    "        \"\"\"Clear the cache\"\"\"\n",
    "        self._cache.clear()\n",
    "        print(\"ðŸ§¹ Cache cleared\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to demonstrate LexiFix usage with dictionary input\"\"\"\n",
    "    try:\n",
    "        # Initialize the LexiFix agent\n",
    "        agent = LexiFix()\n",
    "        \n",
    "        # Example 1: Using dictionary input\n",
    "        print(\"=\" * 50)\n",
    "        print(\"ðŸ“ Example 1: Dictionary Input\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        input_data = {\n",
    "            \"text\": \"the moon is big i think about her everynight and my soul is in chaos\",\n",
    "            \"correction_focus\": \"poetic expression and imagery\",\n",
    "            \"preserve_structure\": False,\n",
    "            \"output_format\": \"text\"\n",
    "        }\n",
    "        \n",
    "        result = agent.fix_text(input_data)\n",
    "        \n",
    "        if result.get(\"success\"):\n",
    "            print(\"ðŸ› ï¸ LexiFix Output:\")\n",
    "            print(f\"Original: {result['original_text']}\")\n",
    "            print(f\"Fixed: {result['fixed_text']}\")\n",
    "            print(f\"Focus: {result['correction_focus']}\")\n",
    "            print(f\"Word Count: {result['word_count']}\")\n",
    "        else:\n",
    "            print(result.get(\"error\", \"Unknown error\"))\n",
    "        \n",
    "        # Example 2: Using convenience methods\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ðŸ“ Example 2: Convenience Methods\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        sample_text = \"i love you so much but i dont know how to say it properly\"\n",
    "        \n",
    "        print(\"ðŸ“ Grammar Focus:\")\n",
    "        grammar_result = agent.fix_grammar(sample_text)\n",
    "        if grammar_result.get(\"success\"):\n",
    "            print(grammar_result[\"fixed_text\"])\n",
    "        \n",
    "        print(\"\\nðŸŒŠ Flow Focus:\")\n",
    "        flow_result = agent.fix_flow(sample_text)\n",
    "        if flow_result.get(\"success\"):\n",
    "            print(flow_result[\"fixed_text\"])\n",
    "        \n",
    "        print(\"\\nðŸŽ­ Poetry Focus:\")\n",
    "        poetry_result = agent.fix_poetry(sample_text)\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"ðŸ“‹ Cache Demonstration\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Process same text again to demonstrate caching\n",
    "        cached_result = agent.fix_text(input_data)\n",
    "        print(\"Cache Stats:\", agent.get_cache_stats())\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Application Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c509a48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franz Kafka (3 July 1883 â€“ 3 June 1924) was a novelist and writer from Prague who was Jewish, Austrian, and Czech and wrote in German. He is widely regarded as a major figure of 20th-century literature. His work fuses elements of realism and the fantastique, and typically features isolated protagonists facing bizarre or surreal predicaments and incomprehensible socio-bureaucratic powers.\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "wikipedia.set_lang(\"en\")  # Force English\n",
    "\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "try:\n",
    "    summary = wikipedia.summary(\"Franz Kafka\", sentences=3)\n",
    "    print(summary)\n",
    "except wikipedia.exceptions.DisambiguationError as e:\n",
    "    print(f\"âŒ Disambiguation Error! Suggestions: {e.options}\")\n",
    "except wikipedia.exceptions.PageError:\n",
    "    print(\"âŒ Page not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Unexpected Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a91d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Franz Kafka (3 July 1883 â€“ 3 June 1924) was a novelist and writer from Prague who was Jewish,\n",
      "Austrian, and Czech and wrote in German. He is widely regarded as a major figure of 20th-century\n",
      "literature. His work fuses elements of realism and the fantastique, and typically features isolated\n",
      "protagonists facing bizarre or surreal predicaments and incomprehensible socio-bureaucratic powers.\n",
      "The term Kafkaesque has entered the lexicon to describe bizarre situations like those depicted in\n",
      "his writing. The domain of mystical parables overlaps with the alienating experience of urban life's\n",
      "indecipherable complexities in these stories. His best-known works include the novella The\n",
      "Metamorphosis (1915) and the novels The Trial (1924) and The Castle (1926).   Though the novels and\n",
      "short stories that Kafka wrote are typically invoked in his prÃ©cis, he is also celebrated for his\n",
      "brief fables and aphorisms. Like his longer fiction, these sketches may be brutal in some aspects,\n",
      "but their dreadfulness is frequently funny. A close acquaintance of Kafka's remarks that both his\n",
      "audience and the author himself sometimes laughed so much during readings that Kafka could not\n",
      "continue in his delivery, finding it necessary to collect himself before completing his recitation\n",
      "of the work.  The parables are sometimes noted for their resemblance to Chasidic fairy tales, in a\n",
      "universe where the transcendental source of authority is absent or unknowable. Kafka's impact is\n",
      "evident in the frequent reception of his writing as a form of prophetic or premonitory vision,\n",
      "anticipating the character of a totalitarian future in the nightmarish logic of his presentation of\n",
      "the lived-present. These perceptions appear in the way that he renders the world inhabited by his\n",
      "characters and in his commentaries written in diaries, letters and aphorisms.   Kafka was born into\n",
      "a middle-class German- and Yiddish-speaking Czech Jewish family in Prague, the capital of the\n",
      "Kingdom of Bohemia, which belonged to the Austro-Hungarian Empire (later the capital of\n",
      "Czechoslovakia and the Czech Republic). He trained as a lawyer, and after completing his legal\n",
      "education was employed full-time in various legal and insurance jobs. His professional obligations\n",
      "led to internal conflict as he felt that his true vocation was writing. Only a minority of his works\n",
      "were published during his life; the story-collections Contemplation (1912) and A Country Doctor\n",
      "(1919), and individual stories, such as his novella The Metamorphosis, were published in literary\n",
      "magazines, but they received little attention. He wrote hundreds of letters to family and close\n",
      "friends, including his father, with whom he had a strained and formal relationship. He became\n",
      "engaged to several women but never married. He died relatively unknown in 1924 of tuberculosis, aged\n",
      "40. Kafka was a prolific writer, but he burned an estimated 90 percent of his total work due to\n",
      "persistent struggles with self-doubt. Much of the remaining 10 percent is lost or otherwise\n",
      "unpublished. In his will, Kafka instructed his close friend and literary executor, Max Brod, to\n",
      "destroy his unfinished works, including his novels The Trial, The Castle, and Amerika (1927), but\n",
      "Brod ignored these instructions and had much of his work published.  Kafka's writings began to\n",
      "receive the highest possible critical acclaim when they were re-released amidst the imposition of\n",
      "the Nuremberg Racial Hygiene Laws in 1935 as a complete set by Schocken, however distribution and\n",
      "broad awareness of these works was stymied by the totalitarian atmosphere of the Nazi regime. The\n",
      "final volumes of this set were released after Schocken was forced to relocate to Prague. The works\n",
      "became more famous in German-speaking countries after World War II, influencing German literature,\n",
      "and its influence spread elsewhere in the world in the 1960s. A critical edition of his complete\n",
      "works, including many elements that had been edited out by Brod in the earlier Schocken collection,\n",
      "was released by S. Fischer Verlag in the final decades of the 20th century.  It has also influenced\n",
      "artists, composers, film-makers, historians, religious scholars, cultural theorists and\n",
      "philosophers.\n"
     ]
    }
   ],
   "source": [
    "def format_paragraph(summary, max_length=120):\n",
    "    words = summary.split()\n",
    "    lines = []\n",
    "    current_line = []\n",
    "\n",
    "    for word in words:\n",
    "        current_line.append(word)\n",
    "        if len(\" \".join(current_line)) >= max_length:\n",
    "            lines.append(\" \".join(current_line))\n",
    "            current_line = []\n",
    "\n",
    "    if current_line:\n",
    "        lines.append(\" \".join(current_line))\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "import textwrap\n",
    "\n",
    "summary = wikipedia.summary(\"Franz Kafka\")\n",
    "print(textwrap.fill(summary, width=100))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
